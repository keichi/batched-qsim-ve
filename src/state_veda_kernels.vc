// vim: set ft=c:
#pragma _NEC options "-O4 -finline-functions -report-all"
#pragma _NEC options "-fdiag-inline=0 -fdiag-parallel=0 -fdiag-vector=0"

#include <complex.h>
#include <math.h>

#include <asl.h>
#include <veda_device.h>

#define UINT unsigned int
#define ITYPE unsigned long long

static asl_random_t rng;

__attribute__((constructor)) void init()
{
    asl_library_initialize();

    asl_random_create(&rng, ASL_RANDOMMETHOD_MT19937);
}

__attribute__((destructor)) void fini()
{
    asl_random_destroy(rng);

    asl_library_finalize();
}

void get_vector(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, VEDAdeviceptr sv_ptr,
                UINT sample, UINT batch_size, UINT n)
{
    const double *state_re = NULL, *state_im = NULL;
    double  *sv = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);
    vedaMemPtr((void **)&sv, sv_ptr);

    for (ITYPE i = 0; i < 1ULL << n; i++) {
        sv[(i << 1)] = state_re[sample + i * batch_size];
        sv[(i << 1) + 1] = state_im[sample + i * batch_size];
    }
}

void get_probability(double *prob, VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, UINT i,
                     UINT batch_size, UINT n)
{
    const double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    *prob = 0.0;

    for (UINT sample = 0; sample < batch_size; sample++) {
        double re = state_re[sample + i * batch_size];
        double im = state_im[sample + i * batch_size];

        *prob += re * re + im * im;
    }

    *prob /= batch_size;
}

void set_zero_state(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << n; i++) {
#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            state_re[sample + i * batch_size] = 0;
            state_im[sample + i * batch_size] = 0;
        }
    }

#pragma omp simd
    for (int sample = 0; sample < batch_size; sample++) {
        state_re[sample] = 1;
        state_im[sample] = 0;
    }
}

void act_single_qubit_gate(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr,
                           double matrix_re[2][2], double matrix_im[2][2], UINT target,
                           UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    ITYPE mask = 1ULL << target;
    ITYPE lo_mask = mask - 1;
    ITYPE hi_mask = ~lo_mask;

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 1); i++) {
        ITYPE i0 = ((i & hi_mask) << 1) | (i & lo_mask);
        ITYPE i1 = i0 | mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double tmp0_re = state_re[sample + i0 * batch_size];
            double tmp0_im = state_im[sample + i0 * batch_size];
            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i0 * batch_size] =
                matrix_re[0][0] * tmp0_re - matrix_im[0][0] * tmp0_im + matrix_re[0][1] * tmp1_re -
                matrix_im[0][1] * tmp1_im;
            state_im[sample + i0 * batch_size] =
                matrix_re[0][0] * tmp0_im + matrix_im[0][0] * tmp0_re + matrix_re[0][1] * tmp1_im +
                matrix_im[0][1] * tmp1_re;

            state_re[sample + i1 * batch_size] =
                matrix_re[1][0] * tmp0_re - matrix_im[1][0] * tmp0_im + matrix_re[1][1] * tmp1_re -
                matrix_im[1][1] * tmp1_im;
            state_im[sample + i1 * batch_size] =
                matrix_re[1][0] * tmp0_im + matrix_im[1][0] * tmp0_re + matrix_re[1][1] * tmp1_im +
                matrix_im[1][1] * tmp1_re;
        }
    }
}

void act_two_qubit_gate(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr,
                        double matrix_re[4][4], double matrix_im[4][4], UINT target, UINT control,
                        UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    ITYPE target_mask = 1ULL << target;
    ITYPE control_mask = 1ULL << control;

    UINT minqubit_index = fmin(target, control);
    UINT max_qubit_index = fmax(target, control);
    ITYPE minqubit_mask = 1ULL << minqubit_index;
    ITYPE max_qubit_mask = 1ULL << (max_qubit_index - 1);
    ITYPE lo_mask = minqubit_mask - 1;
    ITYPE mid_mask = (max_qubit_mask - 1) ^ lo_mask;
    ITYPE hi_mask = ~(max_qubit_mask - 1);

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 2); i++) {
        ITYPE i00 = ((i & hi_mask) << 2) | ((i & mid_mask) << 1) | ((i & lo_mask));
        ITYPE i01 = i00 | target_mask;
        ITYPE i10 = i00 | control_mask;
        ITYPE i11 = i00 | control_mask | target_mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double tmp00_re = state_re[sample + i00 * batch_size];
            double tmp00_im = state_im[sample + i00 * batch_size];
            double tmp01_re = state_re[sample + i01 * batch_size];
            double tmp01_im = state_im[sample + i01 * batch_size];
            double tmp10_re = state_re[sample + i10 * batch_size];
            double tmp10_im = state_im[sample + i10 * batch_size];
            double tmp11_re = state_re[sample + i11 * batch_size];
            double tmp11_im = state_im[sample + i11 * batch_size];

            state_re[sample + i00 * batch_size] =
                matrix_re[0][0] * tmp00_re - matrix_im[0][0] * tmp00_im +
                matrix_re[0][1] * tmp01_re - matrix_im[0][1] * tmp01_im +
                matrix_re[0][2] * tmp10_re - matrix_im[0][2] * tmp10_im +
                matrix_re[0][3] * tmp11_re - matrix_im[0][3] * tmp11_im;
            state_im[sample + i00 * batch_size] =
                matrix_re[0][0] * tmp00_im + matrix_im[0][0] * tmp00_re +
                matrix_re[0][1] * tmp01_im + matrix_im[0][1] * tmp01_re +
                matrix_re[0][2] * tmp10_im + matrix_im[0][2] * tmp10_re +
                matrix_re[0][3] * tmp11_im + matrix_im[0][3] * tmp11_re;

            state_re[sample + i01 * batch_size] =
                matrix_re[1][0] * tmp00_re - matrix_im[1][0] * tmp00_im +
                matrix_re[1][1] * tmp01_re - matrix_im[1][1] * tmp01_im +
                matrix_re[1][2] * tmp10_re - matrix_im[1][2] * tmp10_im +
                matrix_re[1][3] * tmp11_re - matrix_im[1][3] * tmp11_im;
            state_im[sample + i01 * batch_size] =
                matrix_re[1][0] * tmp00_im + matrix_im[1][0] * tmp00_re +
                matrix_re[1][1] * tmp01_im + matrix_im[1][1] * tmp01_re +
                matrix_re[1][2] * tmp10_im + matrix_im[1][2] * tmp10_re +
                matrix_re[1][3] * tmp11_im + matrix_im[1][3] * tmp11_re;

            state_re[sample + i10 * batch_size] =
                matrix_re[2][0] * tmp00_re - matrix_im[2][0] * tmp00_im +
                matrix_re[2][1] * tmp01_re - matrix_im[2][1] * tmp01_im +
                matrix_re[2][2] * tmp10_re - matrix_im[2][2] * tmp10_im +
                matrix_re[2][3] * tmp11_re - matrix_im[2][3] * tmp11_im;
            state_im[sample + i10 * batch_size] =
                matrix_re[2][0] * tmp00_im + matrix_im[2][0] * tmp00_re +
                matrix_re[2][1] * tmp01_im + matrix_im[2][1] * tmp01_re +
                matrix_re[2][2] * tmp10_im + matrix_im[2][2] * tmp10_re +
                matrix_re[2][3] * tmp11_im + matrix_im[2][3] * tmp11_re;

            state_re[sample + i11 * batch_size] =
                matrix_re[3][0] * tmp00_re - matrix_im[3][0] * tmp00_im +
                matrix_re[3][1] * tmp01_re - matrix_im[3][1] * tmp01_im +
                matrix_re[3][2] * tmp10_re - matrix_im[3][2] * tmp10_im +
                matrix_re[3][3] * tmp11_re - matrix_im[3][3] * tmp11_im;
            state_im[sample + i11 * batch_size] =
                matrix_re[3][0] * tmp00_im + matrix_im[3][0] * tmp00_re +
                matrix_re[3][1] * tmp01_im + matrix_im[3][1] * tmp01_re +
                matrix_re[3][2] * tmp10_im + matrix_im[3][2] * tmp10_re +
                matrix_re[3][3] * tmp11_im + matrix_im[3][3] * tmp11_re;
        }
    }
}

void act_rx_gate(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, VEDAdeviceptr theta_ptr,
                 UINT target, UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL, *theta = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);
    vedaMemPtr((void **)&theta, theta_ptr);

    ITYPE mask = 1ULL << target;
    ITYPE lo_mask = mask - 1;
    ITYPE hi_mask = ~lo_mask;

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 1); i++) {
        ITYPE i0 = ((i & hi_mask) << 1) | (i & lo_mask);
        ITYPE i1 = i0 | mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double cos_half = cos(theta[sample] / 2);
            double sin_half = sin(theta[sample] / 2);

            double tmp0_re = state_re[sample + i0 * batch_size];
            double tmp0_im = state_im[sample + i0 * batch_size];
            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i0 * batch_size] = cos_half * tmp0_re + sin_half * tmp1_im;
            state_im[sample + i0 * batch_size] = cos_half * tmp0_im - sin_half * tmp1_re;

            state_re[sample + i1 * batch_size] = sin_half * tmp0_im + cos_half * tmp1_re;
            state_im[sample + i1 * batch_size] = -sin_half * tmp0_re + cos_half * tmp1_im;
        }
    }
}

void act_ry_gate(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, VEDAdeviceptr theta_ptr,
                 UINT target, UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL, *theta = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);
    vedaMemPtr((void **)&theta, theta_ptr);

    ITYPE mask = 1ULL << target;
    ITYPE lo_mask = mask - 1;
    ITYPE hi_mask = ~lo_mask;

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 1); i++) {
        ITYPE i0 = ((i & hi_mask) << 1) | (i & lo_mask);
        ITYPE i1 = i0 | mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double cos_half = cos(theta[sample] / 2);
            double sin_half = sin(theta[sample] / 2);

            double tmp0_re = state_re[sample + i0 * batch_size];
            double tmp0_im = state_im[sample + i0 * batch_size];
            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i0 * batch_size] = cos_half * tmp0_re + sin_half * tmp1_im;
            state_im[sample + i0 * batch_size] = cos_half * tmp0_im - sin_half * tmp1_re;

            state_re[sample + i1 * batch_size] = sin_half * tmp0_im + cos_half * tmp1_re;
            state_im[sample + i1 * batch_size] = -sin_half * tmp0_re + cos_half * tmp1_im;
        }
    }
}

void act_rz_gate(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, VEDAdeviceptr theta_ptr,
                 UINT target, UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL, *theta = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);
    vedaMemPtr((void **)&theta, theta_ptr);

    ITYPE mask = 1ULL << target;
    ITYPE lo_mask = mask - 1;
    ITYPE hi_mask = ~lo_mask;

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 1); i++) {
        ITYPE i0 = ((i & hi_mask) << 1) | (i & lo_mask);
        ITYPE i1 = i0 | mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double cos_half = cos(theta[sample] / 2);
            double sin_half = sin(theta[sample] / 2);

            double tmp0_re = state_re[sample + i0 * batch_size];
            double tmp0_im = state_im[sample + i0 * batch_size];
            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i0 * batch_size] = cos_half * tmp0_re + sin_half * tmp0_im;
            state_im[sample + i0 * batch_size] = cos_half * tmp0_im - sin_half * tmp0_re;

            state_re[sample + i1 * batch_size] = cos_half * tmp1_re - sin_half * tmp1_im;
            state_im[sample + i1 * batch_size] = cos_half * tmp1_im + sin_half * tmp1_re;
        }
    }
}

void act_p_gate(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, VEDAdeviceptr theta_ptr,
                 UINT target, UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL, *theta = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);
    vedaMemPtr((void **)&theta, theta_ptr);

    ITYPE mask = 1ULL << target;
    ITYPE lo_mask = mask - 1;
    ITYPE hi_mask = ~lo_mask;

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 1); i++) {
        ITYPE i0 = ((i & hi_mask) << 1) | (i & lo_mask);
        ITYPE i1 = i0 | mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double cos_ = cos(theta[sample] / 2);
            double sin_ = sin(theta[sample] / 2);

            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i1 * batch_size] = cos_ * tmp1_re - sin_ * tmp1_im;
            state_im[sample + i1 * batch_size] = cos_ * tmp1_im + sin_ * tmp1_re;
        }
    }
}

void act_x_gate_opt(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, UINT target,
                    UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    ITYPE mask = 1ULL << target;
    ITYPE lo_mask = mask - 1;
    ITYPE hi_mask = ~lo_mask;

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 1); i++) {
        ITYPE i0 = ((i & hi_mask) << 1) | (i & lo_mask);
        ITYPE i1 = i0 | mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double tmp0_re = state_re[sample + i0 * batch_size];
            double tmp0_im = state_im[sample + i0 * batch_size];
            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i0 * batch_size] = tmp1_re;
            state_im[sample + i0 * batch_size] = tmp1_im;

            state_re[sample + i1 * batch_size] = tmp0_re;
            state_im[sample + i1 * batch_size] = tmp0_im;
        }
    }
}

void act_y_gate_opt(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, UINT target,
                    UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    ITYPE mask = 1ULL << target;
    ITYPE lo_mask = mask - 1;
    ITYPE hi_mask = ~lo_mask;

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 1); i++) {
        ITYPE i0 = ((i & hi_mask) << 1) | (i & lo_mask);
        ITYPE i1 = i0 | mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double tmp0_re = state_re[sample + i0 * batch_size];
            double tmp0_im = state_im[sample + i0 * batch_size];
            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i0 * batch_size] = tmp1_im;
            state_im[sample + i0 * batch_size] = -tmp1_re;

            state_re[sample + i1 * batch_size] = tmp0_im;
            state_im[sample + i1 * batch_size] = -tmp0_re;
        }
    }
}

void act_z_gate_opt(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, UINT target,
                    UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    ITYPE mask = 1ULL << target;
    ITYPE lo_mask = mask - 1;
    ITYPE hi_mask = ~lo_mask;

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 1); i++) {
        ITYPE i0 = ((i & hi_mask) << 1) | (i & lo_mask);
        ITYPE i1 = i0 | mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i1 * batch_size] = -tmp1_re;
            state_im[sample + i1 * batch_size] = -tmp1_im;
        }
    }
}

void act_cnot_gate_opt(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, UINT target,
                       UINT control, UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    ITYPE target_mask = 1ULL << target;
    ITYPE control_mask = 1ULL << control;

    UINT minqubit_index = fmin(target, control);
    UINT max_qubit_index = fmax(target, control);
    ITYPE minqubit_mask = 1ULL << minqubit_index;
    ITYPE max_qubit_mask = 1ULL << (max_qubit_index - 1);
    ITYPE lo_mask = minqubit_mask - 1;
    ITYPE mid_mask = (max_qubit_mask - 1) ^ lo_mask;
    ITYPE hi_mask = ~(max_qubit_mask - 1);

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 2); i++) {
        ITYPE i00 = ((i & hi_mask) << 2) | ((i & mid_mask) << 1) | ((i & lo_mask));
        ITYPE i10 = i00 | control_mask;
        ITYPE i11 = i00 | control_mask | target_mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double tmp10_re = state_re[sample + i10 * batch_size];
            double tmp10_im = state_im[sample + i10 * batch_size];
            double tmp11_re = state_re[sample + i11 * batch_size];
            double tmp11_im = state_im[sample + i11 * batch_size];

            state_re[sample + i10 * batch_size] = tmp11_re;
            state_im[sample + i10 * batch_size] = tmp11_im;

            state_re[sample + i11 * batch_size] = tmp10_re;
            state_im[sample + i11 * batch_size] = tmp10_im;
        }
    }
}

void act_cx_gate_opt(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, UINT target,
                     UINT control, UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    ITYPE target_mask = 1ULL << target;
    ITYPE control_mask = 1ULL << control;

    UINT minqubit_index = fmin(target, control);
    UINT max_qubit_index = fmax(target, control);
    ITYPE minqubit_mask = 1ULL << minqubit_index;
    ITYPE max_qubit_mask = 1ULL << (max_qubit_index - 1);
    ITYPE lo_mask = minqubit_mask - 1;
    ITYPE mid_mask = (max_qubit_mask - 1) ^ lo_mask;
    ITYPE hi_mask = ~(max_qubit_mask - 1);

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 2); i++) {
        ITYPE i00 = ((i & hi_mask) << 2) | ((i & mid_mask) << 1) | ((i & lo_mask));
        ITYPE i10 = i00 | control_mask;
        ITYPE i11 = i00 | control_mask | target_mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double tmp10_re = state_re[sample + i10 * batch_size];
            double tmp10_im = state_im[sample + i10 * batch_size];
            double tmp11_re = state_re[sample + i11 * batch_size];
            double tmp11_im = state_im[sample + i11 * batch_size];

            state_re[sample + i10 * batch_size] = tmp11_re;
            state_im[sample + i10 * batch_size] = tmp11_im;
            state_re[sample + i11 * batch_size] = tmp10_re;
            state_im[sample + i11 * batch_size] = tmp10_im;
        }
    }
}

void act_cz_gate_opt(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr, UINT target,
                     UINT control, UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    ITYPE target_mask = 1ULL << target;
    ITYPE control_mask = 1ULL << control;

    UINT minqubit_index = fmin(target, control);
    UINT max_qubit_index = fmax(target, control);
    ITYPE minqubit_mask = 1ULL << minqubit_index;
    ITYPE max_qubit_mask = 1ULL << (max_qubit_index - 1);
    ITYPE lo_mask = minqubit_mask - 1;
    ITYPE mid_mask = (max_qubit_mask - 1) ^ lo_mask;
    ITYPE hi_mask = ~(max_qubit_mask - 1);

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 2); i++) {
        ITYPE i00 = ((i & hi_mask) << 2) | ((i & mid_mask) << 1) | ((i & lo_mask));
        ITYPE i11 = i00 | control_mask | target_mask;

#pragma omp simd
        for (int sample = 0; sample < batch_size; sample++) {
            double tmp11_re = state_re[sample + i11 * batch_size];
            double tmp11_im = state_im[sample + i11 * batch_size];

            state_re[sample + i11 * batch_size] = -tmp11_re;
            state_im[sample + i11 * batch_size] = -tmp11_im;
        }
    }
}

void act_depolarizing_gate_1q(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr,
                              VEDAdeviceptr dice_ptr, VEDAdeviceptr x_samples_ptr,
                              VEDAdeviceptr y_samples_ptr, VEDAdeviceptr z_samples_ptr, double prob,
                              UINT target, UINT batch_size, UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    int *x_samples = NULL, *y_samples = NULL, *z_samples = NULL;
    vedaMemPtr((void **)&x_samples, x_samples_ptr);
    vedaMemPtr((void **)&y_samples, y_samples_ptr);
    vedaMemPtr((void **)&z_samples, z_samples_ptr);

    double *dice = NULL;
    vedaMemPtr((void **)&dice, dice_ptr);

    asl_random_generate_d(rng, batch_size, dice);

    UINT nx_samples = 0, ny_samples = 0, nz_samples = 0;
    for (int sample = 0; sample < batch_size; sample++) {
        if (dice[sample] < prob / 3.0) {
            x_samples[nx_samples++] = sample;
        } else if (dice[sample] < prob * 2.0 / 3.0) {
            y_samples[ny_samples++] = sample;
        } else if (dice[sample] < prob) {
            z_samples[nz_samples++] = sample;
        }
    }

    ITYPE mask = 1ULL << target;
    ITYPE lo_mask = mask - 1;
    ITYPE hi_mask = ~lo_mask;

#pragma omp parallel for
    for (ITYPE i = 0; i < 1ULL << (n - 1); i++) {
        ITYPE i0 = ((i & hi_mask) << 1) | (i & lo_mask);
        ITYPE i1 = i0 | mask;

#pragma omp simd
        for (int j = 0; j < nx_samples; j++) {
            int sample = x_samples[j];

            double tmp0_re = state_re[sample + i0 * batch_size];
            double tmp0_im = state_im[sample + i0 * batch_size];
            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i0 * batch_size] = tmp1_re;
            state_im[sample + i0 * batch_size] = tmp1_im;
            state_re[sample + i1 * batch_size] = tmp0_re;
            state_im[sample + i1 * batch_size] = tmp0_im;
        }

#pragma omp simd
        for (int j = 0; j < ny_samples; j++) {
            int sample = y_samples[j];

            double tmp0_re = state_re[sample + i0 * batch_size];
            double tmp0_im = state_im[sample + i0 * batch_size];
            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i0 * batch_size] = tmp1_im;
            state_im[sample + i0 * batch_size] = -tmp1_re;
            state_re[sample + i1 * batch_size] = tmp0_im;
            state_im[sample + i1 * batch_size] = -tmp0_re;
        }

#pragma omp simd
        for (int j = 0; j < nz_samples; j++) {
            int sample = z_samples[j];

            double tmp1_re = state_re[sample + i1 * batch_size];
            double tmp1_im = state_im[sample + i1 * batch_size];

            state_re[sample + i1 * batch_size] = -tmp1_re;
            state_im[sample + i1 * batch_size] = -tmp1_im;
        }
    }
}

static UINT insert_zero_to_basis_index(UINT basis_index, UINT insert_index)
{
    UINT mask = (1ULL << insert_index) - 1;
    UINT temp_basis = (basis_index >> insert_index) << (insert_index + 1);
    return temp_basis | (basis_index & mask);
}

static double complex PHASE_90ROT[] = {1.0, 1.0i, -1.0, -1.0i};

void observe(VEDAdeviceptr state_re_ptr, VEDAdeviceptr state_im_ptr,
             VEDAdeviceptr bit_flip_mask_ptr, VEDAdeviceptr phase_flip_mask_ptr,
             VEDAdeviceptr coef_ptr, VEDAdeviceptr expectation_ptr, UINT num_terms, UINT batch_size,
             UINT n)
{
    double *state_re = NULL, *state_im = NULL;
    vedaMemPtr((void **)&state_re, state_re_ptr);
    vedaMemPtr((void **)&state_im, state_im_ptr);

    UINT *bit_flip_masks = NULL, *phase_flip_masks = NULL;
    double complex *coefs = NULL, *expectations = NULL;
    vedaMemPtr((void **)&bit_flip_masks, bit_flip_mask_ptr);
    vedaMemPtr((void **)&phase_flip_masks, phase_flip_mask_ptr);
    vedaMemPtr((void **)&coefs, coef_ptr);
    vedaMemPtr((void **)&expectations, expectation_ptr);

#pragma omp simd
    for (UINT sample = 0; sample < batch_size; sample++) {
        expectations[sample] = 0.0;
    }

     for (UINT term_id = 0; term_id < num_terms; term_id++) {
        UINT bit_flip_mask = bit_flip_masks[term_id];
        UINT phase_flip_mask = phase_flip_masks[term_id];
        double complex coef = coefs[term_id];

        if (bit_flip_mask == 0) {
             for (UINT idx = 0; idx < 1ULL << (n - 1); idx++) {
                UINT idx1 = idx << 1;
                UINT idx2 = idx1 | 1;

#pragma omp simd
                for (UINT sample = 0; sample < batch_size; sample++) {
                    double tmp1 =
                        state_re[sample + idx1 * batch_size] * state_re[sample + idx1 * batch_size]
                      + state_im[sample + idx1 * batch_size] * state_im[sample + idx1 * batch_size];
                    if (__builtin_popcount(idx1 & phase_flip_mask) & 1) tmp1 = -tmp1;

                    double tmp2 =
                        state_re[sample + idx2 * batch_size] * state_re[sample + idx2 * batch_size]
                      + state_im[sample + idx2 * batch_size] * state_im[sample + idx2 * batch_size];
                    if (__builtin_popcount(idx2 & phase_flip_mask) & 1) tmp2 = -tmp2;

                    expectations[sample] += coef * (tmp1 + tmp2);
                }
            }
        } else {
             for (UINT idx = 0; idx < 1ULL << (n - 1); idx++) {
                UINT pivot = sizeof(UINT) * 8 - __builtin_clz(bit_flip_mask) - 1;
                UINT global_phase_90rot_count = __builtin_popcount(bit_flip_mask & phase_flip_mask);
                double complex global_phase = PHASE_90ROT[global_phase_90rot_count % 4];
                UINT basis_0 = insert_zero_to_basis_index(idx, pivot);
                UINT basis_1 = basis_0 ^ bit_flip_mask;

#pragma omp simd
                for (UINT sample = 0; sample < batch_size; sample++) {
                    double complex tmp1 =
                        state_re[sample + basis_0 * batch_size] + state_im[sample + basis_0 * batch_size] * I;
                    double complex tmp2 =
                        state_im[sample + basis_0 * batch_size] + state_im[sample + basis_1 * batch_size] * I;
                    double tmp = creal(tmp1 * conj(tmp2) * global_phase * 2.);
                    if (__builtin_popcount(basis_0 & phase_flip_mask) & 1) tmp = -tmp;
                    expectations[sample] += coef * tmp;
                }
            }
        }
    }
}
